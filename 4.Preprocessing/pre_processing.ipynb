{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mdw7Ubc6tVWO"
   },
   "source": [
    "# **What is data preprocessing?**\n",
    "\n",
    "Data preprocessing is a data mining technique that involves transforming raw data into an understandable format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iaV3aWUkQ-ZK"
   },
   "source": [
    "**Load the library to run the functions**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "qg7zsMLasvMB"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_regression\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.datasets import load_iris\n",
    "from scipy.stats import skew\n",
    "from numpy import array \n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.datasets import make_friedman1\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVR\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.datasets import make_classification\n",
    "from scipy.stats import kurtosis\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm\n",
    "dataset = pd.DataFrame()\n",
    "\n",
    "\n",
    "X = pd.DataFrame()\n",
    "y = pd.DataFrame()\n",
    "dataset_minmax_pca = pd.DataFrame()\n",
    "dataset_minmax = pd.DataFrame()\n",
    "dataset_minmax_corr = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uw58MXI2O2gT",
    "outputId": "bc7c4c90-48e7-4fce-ab07-3fdbc9d006c1"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h0D7lIOatwyt"
   },
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "DMl-McdSRFkD"
   },
   "outputs": [],
   "source": [
    "def loaddata(file):\n",
    "    dataset =  pd.read_csv(file)\n",
    "    dataset.head(5)\n",
    "    dataset = pd.DataFrame(dataset).fillna(0)\n",
    "#   dataset = pd.get_dummies(dataset,columns= ['attack_cat'])\n",
    "    X=dataset.drop(columns=['label'], axis = 1)\n",
    "    X1=X\n",
    "    print(kurtosis(X))\n",
    "    print(print(\"Skewness for data :\",skew(X1)))\n",
    "    y=dataset['label']\n",
    "    return dataset,X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vTHHcfXUM_yA"
   },
   "source": [
    "# 1.**Correlation analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ugc3lxkqvQP2"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "*   Correlation can help in predicting one attribute from another (Great way to impute missing values).\n",
    "*   List itemCorrelation can (sometimes) indicate the presence of a causal relationship.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F4pU4LnuaxVN"
   },
   "source": [
    "**X (train) , y(label)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OvdED17saXgZ"
   },
   "source": [
    "**Remove the highly correlated features : to each other**\n",
    "\n",
    "Advantage: Reduces noise \n",
    "\n",
    "[Reference](https://chrisalbon.com/machine_learning/feature_selection/drop_highly_correlated_features/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Q8oQeNEuBWL"
   },
   "source": [
    "### 1.1**Function to remove highly correlated data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "9ss5-Vi0ah3S"
   },
   "outputs": [],
   "source": [
    "def removeHcorrFeature(percentage,X):\n",
    "  # Selecting all the features with high correlation values with other features\n",
    "    corr_matrix = X.corr().abs()\n",
    "\n",
    "  # Select upper triangle of correlation matrix\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "  # Find index of feature columns with correlation greater than 0.9\n",
    "    o_drop = [column for column in upper.columns if any(upper[column] > percentage)]\n",
    "    print(o_drop)\n",
    "    return o_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FxvA1sa7Nn6S"
   },
   "source": [
    "# 2.**Feature Scaling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rNWPddYc8F-X"
   },
   "source": [
    "### 2.1 **MinMaxScaling**\n",
    "\n",
    "About MinMax Scaler : \n",
    "* This Scaler responds well if the standard deviation is small and when a distribution is not Gaussian.     \n",
    "* This Scaler is sensitive to outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EaBs5LRz8SBj"
   },
   "source": [
    "**Function for min max scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "muclaRD4HZ7Y"
   },
   "outputs": [],
   "source": [
    "def applyMinMax(data):  \n",
    "# scale features\n",
    "    scaler = MinMaxScaler()\n",
    "    model=scaler.fit(data)\n",
    "    scaled_data=model.transform(data)\n",
    "    return scaled_data\n",
    "  #print(data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xtS4J3HgI7eq"
   },
   "source": [
    "### 2.2 **Standard Scaling**\n",
    "\n",
    "About Standard Scaler: \n",
    "* Centering and scaling happen independently on each feature by computing the relevant statistics on the samples in the training set. \n",
    "* This scaler responds well when a distribution is Gaussian.\n",
    "\n",
    "**Function for standard scaler** **bold text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "VIRs5QM4I2Z6"
   },
   "outputs": [],
   "source": [
    "def applyStandardScaler(data):\n",
    "    scaler = StandardScaler()\n",
    "    model = scaler.fit(data)\n",
    "    scaled_data = model.transform(data)\n",
    "  #print(data_set)\n",
    "    return scaled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VAX0OhSRFRhq"
   },
   "source": [
    "## Which scaler to use?\n",
    "\n",
    "This we be decide after we study our dataset for gaussian distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kH2ao0zINIbK"
   },
   "source": [
    "# 3.**Principle component Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F1xiK_WE6-t2"
   },
   "source": [
    "### 3.1**Functions for applying PCA method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "uJ2Rvg5RcV-M"
   },
   "outputs": [],
   "source": [
    "def applyPCA(X, n_com):\n",
    "   #print(data_set)\n",
    "    pca = PCA(n_components=n_com).fit(X)\n",
    "    X_train_pca = pca.transform(X)\n",
    "    print(pca.n_components_)\n",
    "    return X_train_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APmj_xGANH_i"
   },
   "source": [
    "# Main function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FsMtAkKwFRhs"
   },
   "source": [
    "Points to note:\n",
    "\n",
    "1) Scaling is critical while performing Principal Component Analysis(PCA). PCA tries to get the features with maximum variance, and the variance is high for high magnitude features and skews the PCA towards high magnitude features. [Reference](https://towardsdatascience.com/all-about-feature-scaling-bcc0ad75cb35)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "TWh31Ox2NHzq"
   },
   "outputs": [],
   "source": [
    "def without_preprocess(filename):\n",
    "    dataset,X,y=loaddata(filename)\n",
    "    \n",
    "    return X,y,dataset    \n",
    "    #check if the dataset is gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bfIDDDIvNB1H",
    "outputId": "2f5fcc72-90cf-4377-cd6f-75aceee75bd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.80401589e+01  1.41202499e+01  3.25489325e+00  2.24573259e+00\n",
      "  2.21322594e+03  2.96582425e+03  2.61644857e+03  3.27228347e+03\n",
      "  1.49798961e+01 -1.49491386e+00 -1.33661251e+00  1.36968810e+02\n",
      "  2.27856540e+01  2.55141952e+03  3.50271171e+03  6.73801510e+01\n",
      "  9.39548143e+02  3.14482186e+02  2.63843613e+03 -1.99181834e+00\n",
      " -4.33890762e-01 -4.21084764e-01 -1.98316474e+00  1.58251093e+02\n",
      "  3.98225846e+02  2.04622331e+02  1.36950231e+01  8.26080496e+00\n",
      "  3.79268744e+04  8.51365167e+03  1.85341547e+00  5.06444942e+00\n",
      "  5.09737732e+00  5.68070487e+00  2.95083453e+00  2.07832178e+00\n",
      "  7.44189174e+01  1.52188534e+02  6.95250182e+02  4.08548752e+00\n",
      "  1.87480693e+00  6.50723925e+01 -1.56126234e-01]\n",
      "Skewness for data : [ 8.02244778e+00 -3.79926482e+00  1.78400999e+00 -8.54334812e-01\n",
      "  4.25216505e+01  4.11925360e+01  4.79168946e+01  4.43399752e+01\n",
      "  3.38046837e+00 -6.82162799e-01  7.87244421e-01  8.93325379e+00\n",
      "  4.71074517e+00  4.71204072e+01  4.60860573e+01  8.28790196e+00\n",
      "  2.69651543e+01  1.68644480e+01  3.74961937e+01  9.02329957e-02\n",
      "  1.02643995e+00  1.03102097e+00  1.29619022e-01  7.43465322e+00\n",
      "  1.22157498e+01  8.07383079e+00  3.66657133e+00  2.91009252e+00\n",
      "  1.73161986e+02  7.84768225e+01  1.63760490e+00  1.17702406e+00\n",
      "  2.26149264e+00  2.40514560e+00  1.95935606e+00  1.76222832e+00\n",
      "  8.74179143e+00  1.04079634e+01  2.06538422e+01  2.03881929e+00\n",
      "  1.65619962e+00  8.18977365e+00 -6.79430115e-01]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "X,y,dataset=without_preprocess(\"./input/cleaned_dataset_label_encoding.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Dataset for Gaussian Distribution\n",
    "### To decide which scaler to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "KJ3k6JvCMniw",
    "outputId": "434c9df4-9b44-4217-fd91-b1bff225284d"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-60024dc9fd18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplot_GD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-60024dc9fd18>\u001b[0m in \u001b[0;36mplot_GD\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplot_GD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_GD(dataset):\n",
    "  num_features = dataset.columns[dataset.dtypes != 'object']\n",
    "  for i in num_features:\n",
    "    plt.figure()\n",
    "    sns.distplot(dataset[i])\n",
    "plot_GD(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "Since most of the non object data is noramilzed, We would go ahead with standard scaler. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Ntv5GejVT76"
   },
   "source": [
    "# 6.**Save the preprocessed file**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "pre_processing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
