{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16a6780b",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "\n",
    "- Random Forest is combination of many decision trees\n",
    "- It is a classification algorithm.\n",
    "\n",
    "Why do we need Random Forest over Decision Trees?\n",
    "- Though Decision Trees are easy to build, use and interpret, but they are inaccurate\n",
    "- DTs are not very good with unseen data so our Model may not work as desired\n",
    "- Random Forest = Simplicity of DT + Very Good Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36157ca5",
   "metadata": {},
   "source": [
    "## Input\n",
    "\n",
    "1. .csv - produced by pre_processing.ipynb\n",
    "2. The pre_processed input data includes following techniques:\n",
    "   * MinMax Scaling\n",
    "   * PCA\n",
    "   * Correlation\n",
    "\n",
    "## Output/Analysis\n",
    "\n",
    "1. Visualising the accuracy of RF with k-fold validation.\n",
    "2. Comparing the accurancy of RF model with and without PCA.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4aed72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76d0b02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    return pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e77ddf2",
   "metadata": {},
   "source": [
    "# Spilt the input file into test and train dataset\n",
    "\n",
    "I/P: dataframe\n",
    "\n",
    "O/P: x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8c9e261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_training(network_data):\n",
    "    length = len(network_data. columns)\n",
    "    x = network_data.iloc[:,list(range(1,length-1))]\n",
    "    y = network_data.iloc[:,length-1]\n",
    "    print(x)\n",
    "    print(y)\n",
    "    print(\"Shape of x: \", x.shape)\n",
    "    print(\"Shape of y: \", y.shape)\n",
    "    return train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9ffff1",
   "metadata": {},
   "source": [
    "# Split the train dataset into train and Cross validation dataset\n",
    "\n",
    "I/P: x_train, y_train\n",
    "\n",
    "O/P: x_train_new, x_cv, y_train_new, y_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56fd1384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitIntoTrainAndCV(x_train,y_train):\n",
    "    # Splitting train in train and cv data\n",
    "    _x_train_new, _x_cv, _y_train_new, _y_cv = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "    print(_x_train_new.shape, _y_train_new.shape, _x_cv.shape, _y_cv.shape)\n",
    "    return {'x_train_new':_x_train_new, 'x_cv':_x_cv, 'y_train_new': _y_train_new, 'y_cv':_y_cv}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3528006",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning for Random Forest\n",
    "\n",
    "The following hyperparamter tuning has taken reference from:\n",
    "1. https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "2. https://medium.com/@ODSC/optimizing-hyperparameters-for-random-forest-algorithms-in-scikit-learn-d60b7aa07ead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffeb1df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514106f7",
   "metadata": {},
   "source": [
    "Instead of all the above the parameters, we will just focus on tuning a few as given below:\n",
    "We will try adjusting a few of the following set of hyperparameters:\n",
    "1. n_estimators = number of trees in the foreset\n",
    "2. max_features = max number of features considered for splitting a node\n",
    "3. max_depth = max number of levels in each decision tree\n",
    "4. min_samples_split = min number of data points placed in a node before the node is split\n",
    "5. min_samples_leaf = min number of data points allowed in a leaf node\n",
    "6. bootstrap = method for sampling data points (with or without replacement)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ad6de9",
   "metadata": {},
   "source": [
    "To use RandomizedSearchCV, we first need to create a parameter grid to sample from during fitting:\n",
    "\n",
    "Params From reference github\n",
    "- n_estimators=[100,200,300,400]\n",
    "- max_features = Not included\n",
    "- max_depth = [20,22,24]\n",
    "- min_samples_split = [2,4,6]\n",
    "- min_samples_leaf = not included\n",
    "- bootstrap = not included\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a379a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f83ae7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creatingRandomGrid():\n",
    "    # Number of trees in random forest\n",
    "    n_estimators = [100,200,300,400]\n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = [20,22,24]\n",
    "    # Minimum number of samples required to split a node\n",
    "    min_samples_split = [2,4,6]\n",
    "    # Create the random grid\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split}\n",
    "    return random_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f55de400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepToFindOptimalHyperParams(random_grid):\n",
    "    # Use the random grid to search for best hyperparameters\n",
    "    # First create the base model to tune\n",
    "    rf = RandomForestRegressor()\n",
    "    \n",
    "    # Random search of parameters, using 3 fold cross validation, \n",
    "    # search across 100 different combinations, and use all available cores\n",
    "    rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, \n",
    "                                   n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "    return rf_random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5a4d3d",
   "metadata": {},
   "source": [
    "Finally, fit the RandomizedSearchCV object to the data frames containing features and labels and print the optimal hyperparameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27303281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findBestHyperParameters(rf_random, x_train_new, y_train_new):\n",
    "    # Fit the random search model\n",
    "    print(len(x_train_new), len(y_train_new))\n",
    "    rf_random.fit(x_train_new, y_train_new)\n",
    "    bestParamsDict = rf_random.best_params_\n",
    "    return bestParamsDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9e4ce7",
   "metadata": {},
   "source": [
    "# Train the Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba2a7e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAndTestRandomForest(_max_depth,\n",
    "                            _min_samples_split,\n",
    "                            _n_estimators,x_train_new,y_train_new):\n",
    "    clf = RandomForestClassifier(max_depth=_max_depth, \n",
    "                                 min_samples_split = _min_samples_split, \n",
    "                                 n_estimators = _n_estimators)\n",
    "    # Train Random Forest Classifer\n",
    "    clf = clf.fit(x_train_new,y_train_new)\n",
    "    #Predict the response for test dataset\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7409cd",
   "metadata": {},
   "source": [
    "# Test the model and find out its accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "440cfd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tellAcurracyOfModel(clf,x_test,y_test):\n",
    "    y_pred = clf.predict(x_test)\n",
    "    # Model Accuracy, how often is the classifier correct?\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c609a94a",
   "metadata": {},
   "source": [
    "# Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "feb78669",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(network_data):\n",
    "        \n",
    "    x_train,x_test,y_train,y_test = prep_training(network_data)\n",
    "    \n",
    "    newDict = splitIntoTrainAndCV(x_train,y_train)\n",
    "    x_train_new = newDict['x_train_new']\n",
    "    x_cv = newDict['x_cv']\n",
    "    y_train_new = newDict['y_train_new']\n",
    "    y_cv = newDict['y_cv']\n",
    "                    \n",
    "    random_grid = creatingRandomGrid()\n",
    "    pprint(random_grid)\n",
    "    rf_random = prepToFindOptimalHyperParams(random_grid)\n",
    "    bestParamsDict = findBestHyperParameters(rf_random, x_train_new, y_train_new)\n",
    "    \n",
    "    _n_estimators = bestParamsDict['n_estimators']\n",
    "    _min_samples_split = bestParamsDict['min_samples_split']\n",
    "    _max_depth = bestParamsDict['max_depth']\n",
    "    \n",
    "    print(\"The best parameters after hyper paramter tuning of Random Forest are as follows:\")\n",
    "    print(\"n_estimators = \", _n_estimators)\n",
    "    print(\"min_samples_split = \", _min_samples_split)\n",
    "    print(\"max_depth = \",_max_depth)\n",
    "    \n",
    "    clf = trainAndTestRandomForest(_max_depth,_min_samples_split,_n_estimators,x_train_new,y_train_new)\n",
    "    tellAcurracyOfModel(clf,x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73d1131",
   "metadata": {},
   "source": [
    "# Classification with RF after MinMax Scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c477d47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_data = load_data(\"./data_minmax_labelenc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6163ca95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           proto   service  state     spkts     dpkts    sbytes    dbytes  \\\n",
      "0       0.901515  0.000000    0.5  0.000094  0.000000  0.000033  0.000000   \n",
      "1       0.901515  0.000000    0.5  0.000094  0.000000  0.000121  0.000000   \n",
      "2       0.901515  0.000000    0.5  0.000094  0.000000  0.000073  0.000000   \n",
      "3       0.901515  0.000000    0.5  0.000094  0.000000  0.000061  0.000000   \n",
      "4       0.901515  0.000000    0.5  0.000094  0.000000  0.000146  0.000000   \n",
      "...          ...       ...    ...       ...       ...       ...       ...   \n",
      "257668  0.901515  0.166667    0.5  0.000094  0.000000  0.000006  0.000000   \n",
      "257669  0.856061  0.000000    0.4  0.000845  0.000726  0.000042  0.000024   \n",
      "257670  0.901515  0.166667    0.5  0.000094  0.000000  0.000006  0.000000   \n",
      "257671  0.901515  0.166667    0.5  0.000094  0.000000  0.000006  0.000000   \n",
      "257672  0.901515  0.166667    0.5  0.000094  0.000000  0.000006  0.000000   \n",
      "\n",
      "            rate      sttl      dttl  ...  attack_cat_0  attack_cat_1  \\\n",
      "0       0.090909  0.996078  0.000000  ...           0.0           0.0   \n",
      "1       0.125000  0.996078  0.000000  ...           0.0           0.0   \n",
      "2       0.200000  0.996078  0.000000  ...           0.0           0.0   \n",
      "3       0.166667  0.996078  0.000000  ...           0.0           0.0   \n",
      "4       0.100000  0.996078  0.000000  ...           0.0           0.0   \n",
      "...          ...       ...       ...  ...           ...           ...   \n",
      "257668  0.111111  0.996078  0.000000  ...           0.0           0.0   \n",
      "257669  0.000034  0.996078  0.992126  ...           0.0           0.0   \n",
      "257670  0.111111  0.996078  0.000000  ...           0.0           0.0   \n",
      "257671  0.111111  0.996078  0.000000  ...           0.0           0.0   \n",
      "257672  0.111111  0.996078  0.000000  ...           0.0           0.0   \n",
      "\n",
      "        attack_cat_2  attack_cat_3  attack_cat_4  attack_cat_5  attack_cat_6  \\\n",
      "0                0.0           0.0           0.0           0.0           1.0   \n",
      "1                0.0           0.0           0.0           0.0           1.0   \n",
      "2                0.0           0.0           0.0           0.0           1.0   \n",
      "3                0.0           0.0           0.0           0.0           1.0   \n",
      "4                0.0           0.0           0.0           0.0           1.0   \n",
      "...              ...           ...           ...           ...           ...   \n",
      "257668           0.0           0.0           0.0           1.0           0.0   \n",
      "257669           0.0           0.0           0.0           0.0           0.0   \n",
      "257670           0.0           0.0           0.0           1.0           0.0   \n",
      "257671           0.0           0.0           0.0           1.0           0.0   \n",
      "257672           0.0           0.0           0.0           1.0           0.0   \n",
      "\n",
      "        attack_cat_7  attack_cat_8  attack_cat_9  \n",
      "0                0.0           0.0           0.0  \n",
      "1                0.0           0.0           0.0  \n",
      "2                0.0           0.0           0.0  \n",
      "3                0.0           0.0           0.0  \n",
      "4                0.0           0.0           0.0  \n",
      "...              ...           ...           ...  \n",
      "257668           0.0           0.0           0.0  \n",
      "257669           0.0           1.0           0.0  \n",
      "257670           0.0           0.0           0.0  \n",
      "257671           0.0           0.0           0.0  \n",
      "257672           0.0           0.0           0.0  \n",
      "\n",
      "[257673 rows x 51 columns]\n",
      "0         0\n",
      "1         0\n",
      "2         0\n",
      "3         0\n",
      "4         0\n",
      "         ..\n",
      "257668    1\n",
      "257669    1\n",
      "257670    1\n",
      "257671    1\n",
      "257672    1\n",
      "Name: label, Length: 257673, dtype: int64\n",
      "Shape of x:  (257673, 51)\n",
      "Shape of y:  (257673,)\n",
      "(164910, 51) (164910,) (41228, 51) (41228,)\n",
      "{'max_depth': [20, 22, 24],\n",
      " 'min_samples_split': [2, 4, 6],\n",
      " 'n_estimators': [100, 200, 300, 400]}\n",
      "164910 164910\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/divya/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:285: UserWarning: The total space of parameters 36 is smaller than n_iter=100. Running 36 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters after hyper paramter tuning of Random Forest are as follows:\n",
      "n_estimators =  100\n",
      "min_samples_split =  2\n",
      "max_depth =  20\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "main(network_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d026fb",
   "metadata": {},
   "source": [
    "# Classification with RF after MinMax Scaling + Dimension Reduction (using PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9cca6bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# network_data = load_data('dataset_minmax_pca.csv')\n",
    "# main(network_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ad2380",
   "metadata": {},
   "source": [
    "# Classification with RF after MinMax Scaling + Correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "825a9a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# network_data = load_data('dataset_minmax_corr.csv')\n",
    "# main(network_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
