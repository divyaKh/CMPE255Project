{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16a6780b",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "\n",
    "- Random Forest is combination of many decision trees\n",
    "- It is a classification algorithm.\n",
    "\n",
    "Why do we need Random Forest over Decision Trees?\n",
    "- Though Decision Trees are easy to build, use and interpret, but they are inaccurate\n",
    "- DTs are not very good with unseen data so our Model may not work as desired\n",
    "- Random Forest = Simplicity of DT + Very Good Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36157ca5",
   "metadata": {},
   "source": [
    "## Input\n",
    "\n",
    "1. .csv - produced by pre_processing.ipynb\n",
    "2. The pre_processed input data includes following techniques:\n",
    "    #TODO\n",
    "\n",
    "## Output/Analysis\n",
    "\n",
    "1. Visualising the accuracy of RF with k-fold validation.\n",
    "2. Comparing the accurancy of RF model with and without PCA.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4aed72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76d0b02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    return pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f841c579",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_data = load_data('data_minmax.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e77ddf2",
   "metadata": {},
   "source": [
    "# Spilt the input file into test and train dataset\n",
    "\n",
    "I/P: dataframe\n",
    "\n",
    "O/P: x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69d574e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dur</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>sttl</th>\n",
       "      <th>dttl</th>\n",
       "      <th>sload</th>\n",
       "      <th>dload</th>\n",
       "      <th>...</th>\n",
       "      <th>attack_cat_Backdoor</th>\n",
       "      <th>attack_cat_DoS</th>\n",
       "      <th>attack_cat_Exploits</th>\n",
       "      <th>attack_cat_Fuzzers</th>\n",
       "      <th>attack_cat_Generic</th>\n",
       "      <th>attack_cat_Normal</th>\n",
       "      <th>attack_cat_Reconnaissance</th>\n",
       "      <th>attack_cat_Shellcode</th>\n",
       "      <th>attack_cat_Worms</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.833334e-07</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.333334e-07</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.147128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.333335e-08</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142685</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.666667e-07</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            dur     spkts  dpkts    sbytes  dbytes      rate      sttl  dttl  \\\n",
       "0  1.833334e-07  0.000094    0.0  0.000033     0.0  0.090909  0.996078   0.0   \n",
       "1  1.333334e-07  0.000094    0.0  0.000121     0.0  0.125000  0.996078   0.0   \n",
       "2  8.333335e-08  0.000094    0.0  0.000073     0.0  0.200000  0.996078   0.0   \n",
       "3  1.000000e-07  0.000094    0.0  0.000061     0.0  0.166667  0.996078   0.0   \n",
       "4  1.666667e-07  0.000094    0.0  0.000146     0.0  0.100000  0.996078   0.0   \n",
       "\n",
       "      sload  dload  ...  attack_cat_Backdoor  attack_cat_DoS  \\\n",
       "0  0.030121    0.0  ...                  0.0             0.0   \n",
       "1  0.147128    0.0  ...                  0.0             0.0   \n",
       "2  0.142685    0.0  ...                  0.0             0.0   \n",
       "3  0.100200    0.0  ...                  0.0             0.0   \n",
       "4  0.142017    0.0  ...                  0.0             0.0   \n",
       "\n",
       "   attack_cat_Exploits  attack_cat_Fuzzers  attack_cat_Generic  \\\n",
       "0                  0.0                 0.0                 0.0   \n",
       "1                  0.0                 0.0                 0.0   \n",
       "2                  0.0                 0.0                 0.0   \n",
       "3                  0.0                 0.0                 0.0   \n",
       "4                  0.0                 0.0                 0.0   \n",
       "\n",
       "   attack_cat_Normal  attack_cat_Reconnaissance  attack_cat_Shellcode  \\\n",
       "0                1.0                        0.0                   0.0   \n",
       "1                1.0                        0.0                   0.0   \n",
       "2                1.0                        0.0                   0.0   \n",
       "3                1.0                        0.0                   0.0   \n",
       "4                1.0                        0.0                   0.0   \n",
       "\n",
       "   attack_cat_Worms  label  \n",
       "0               0.0      0  \n",
       "1               0.0      0  \n",
       "2               0.0      0  \n",
       "3               0.0      0  \n",
       "4               0.0      0  \n",
       "\n",
       "[5 rows x 207 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8c9e261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_training():\n",
    "    x = network_data.iloc[:,list(range(1,206))]\n",
    "    y = network_data.iloc[:,206]\n",
    "    print(x)\n",
    "    print(y)\n",
    "    print(\"Shape of x: \", x.shape)\n",
    "    print(\"Shape of y: \", y.shape)\n",
    "    return train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "093b0bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           spkts     dpkts    sbytes    dbytes      rate      sttl      dttl  \\\n",
      "0       0.000094  0.000000  0.000033  0.000000  0.090909  0.996078  0.000000   \n",
      "1       0.000094  0.000000  0.000121  0.000000  0.125000  0.996078  0.000000   \n",
      "2       0.000094  0.000000  0.000073  0.000000  0.200000  0.996078  0.000000   \n",
      "3       0.000094  0.000000  0.000061  0.000000  0.166667  0.996078  0.000000   \n",
      "4       0.000094  0.000000  0.000146  0.000000  0.100000  0.996078  0.000000   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "257668  0.000094  0.000000  0.000006  0.000000  0.111111  0.996078  0.000000   \n",
      "257669  0.000845  0.000726  0.000042  0.000024  0.000034  0.996078  0.992126   \n",
      "257670  0.000094  0.000000  0.000006  0.000000  0.111111  0.996078  0.000000   \n",
      "257671  0.000094  0.000000  0.000006  0.000000  0.111111  0.996078  0.000000   \n",
      "257672  0.000094  0.000000  0.000006  0.000000  0.111111  0.996078  0.000000   \n",
      "\n",
      "           sload     dload     sloss  ...  attack_cat_Analysis  \\\n",
      "0       0.030121  0.000000  0.000000  ...                  0.0   \n",
      "1       0.147128  0.000000  0.000000  ...                  0.0   \n",
      "2       0.142685  0.000000  0.000000  ...                  0.0   \n",
      "3       0.100200  0.000000  0.000000  ...                  0.0   \n",
      "4       0.142017  0.000000  0.000000  ...                  0.0   \n",
      "...          ...       ...       ...  ...                  ...   \n",
      "257668  0.008461  0.000000  0.000000  ...                  0.0   \n",
      "257669  0.000001  0.000219  0.000376  ...                  0.0   \n",
      "257670  0.008461  0.000000  0.000000  ...                  0.0   \n",
      "257671  0.008461  0.000000  0.000000  ...                  0.0   \n",
      "257672  0.008461  0.000000  0.000000  ...                  0.0   \n",
      "\n",
      "        attack_cat_Backdoor  attack_cat_DoS  attack_cat_Exploits  \\\n",
      "0                       0.0             0.0                  0.0   \n",
      "1                       0.0             0.0                  0.0   \n",
      "2                       0.0             0.0                  0.0   \n",
      "3                       0.0             0.0                  0.0   \n",
      "4                       0.0             0.0                  0.0   \n",
      "...                     ...             ...                  ...   \n",
      "257668                  0.0             0.0                  0.0   \n",
      "257669                  0.0             0.0                  0.0   \n",
      "257670                  0.0             0.0                  0.0   \n",
      "257671                  0.0             0.0                  0.0   \n",
      "257672                  0.0             0.0                  0.0   \n",
      "\n",
      "        attack_cat_Fuzzers  attack_cat_Generic  attack_cat_Normal  \\\n",
      "0                      0.0                 0.0                1.0   \n",
      "1                      0.0                 0.0                1.0   \n",
      "2                      0.0                 0.0                1.0   \n",
      "3                      0.0                 0.0                1.0   \n",
      "4                      0.0                 0.0                1.0   \n",
      "...                    ...                 ...                ...   \n",
      "257668                 0.0                 1.0                0.0   \n",
      "257669                 0.0                 0.0                0.0   \n",
      "257670                 0.0                 1.0                0.0   \n",
      "257671                 0.0                 1.0                0.0   \n",
      "257672                 0.0                 1.0                0.0   \n",
      "\n",
      "        attack_cat_Reconnaissance  attack_cat_Shellcode  attack_cat_Worms  \n",
      "0                             0.0                   0.0               0.0  \n",
      "1                             0.0                   0.0               0.0  \n",
      "2                             0.0                   0.0               0.0  \n",
      "3                             0.0                   0.0               0.0  \n",
      "4                             0.0                   0.0               0.0  \n",
      "...                           ...                   ...               ...  \n",
      "257668                        0.0                   0.0               0.0  \n",
      "257669                        0.0                   1.0               0.0  \n",
      "257670                        0.0                   0.0               0.0  \n",
      "257671                        0.0                   0.0               0.0  \n",
      "257672                        0.0                   0.0               0.0  \n",
      "\n",
      "[257673 rows x 205 columns]\n",
      "0         0\n",
      "1         0\n",
      "2         0\n",
      "3         0\n",
      "4         0\n",
      "         ..\n",
      "257668    1\n",
      "257669    1\n",
      "257670    1\n",
      "257671    1\n",
      "257672    1\n",
      "Name: label, Length: 257673, dtype: int64\n",
      "Shape of x:  (257673, 205)\n",
      "Shape of y:  (257673,)\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = prep_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9ffff1",
   "metadata": {},
   "source": [
    "# Split the train dataset into train and Cross validation dataset\n",
    "\n",
    "I/P: x_train, y_train\n",
    "\n",
    "O/P: x_train_new, x_cv, y_train_new, y_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56fd1384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting train in train and cv data\n",
    "x_train_new, x_cv, y_train_new, y_cv = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d06ce886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((164910, 205), (164910,), (41228, 205), (41228,), (51535, 205), (51535,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_new.shape, y_train_new.shape, x_cv.shape, y_cv.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3528006",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning for Random Forest\n",
    "\n",
    "The following hyperparamter tuning has taken reference from:\n",
    "1. https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "2. https://medium.com/@ODSC/optimizing-hyperparameters-for-random-forest-algorithms-in-scikit-learn-d60b7aa07ead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffeb1df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd25423d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27b36210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'criterion': 'mse',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': 42,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "print('Parameters currently in use:\\n')\n",
    "pprint(rf.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514106f7",
   "metadata": {},
   "source": [
    "Instead of all the above the parameters, we will just focus on tuning a few as given below:\n",
    "We will try adjusting the following set of hyperparameters:\n",
    "1. n_estimators = number of trees in the foreset\n",
    "2. max_features = max number of features considered for splitting a node\n",
    "3. max_depth = max number of levels in each decision tree\n",
    "4. min_samples_split = min number of data points placed in a node before the node is split\n",
    "5. min_samples_leaf = min number of data points allowed in a leaf node\n",
    "6. bootstrap = method for sampling data points (with or without replacement)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ad6de9",
   "metadata": {},
   "source": [
    "To use RandomizedSearchCV, we first need to create a parameter grid to sample from during fitting:\n",
    "\n",
    "Params From reference github\n",
    "- n_estimators=[100,200,300,400]\n",
    "- max_features = Not included\n",
    "- max_depth = [20,22,24]\n",
    "- min_samples_split = [2,4,6]\n",
    "- min_samples_leaf = not included\n",
    "- bootstrap = not included\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a379a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "249f1649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "# n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "n_estimators = [100,200,300,400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47f912e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of features to consider at every split\n",
    "# max_features = ['auto', 'sqrt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f55de400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum number of levels in tree\n",
    "# max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "# max_depth.append(None)\n",
    "max_depth = [20,22,24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "600b4fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum number of samples required to split a node\n",
    "# min_samples_split = [2, 5, 10]\n",
    "min_samples_split = [2,4,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "951ad514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum number of samples required at each leaf node\n",
    "# min_samples_leaf = [1, 2, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b65c2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method of selecting samples for training each tree\n",
    "# bootstrap = [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f7b14ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the random grid\n",
    "# random_grid = {'n_estimators': n_estimators,\n",
    "#                'max_features': max_features,\n",
    "#                'max_depth': max_depth,\n",
    "#                'min_samples_split': min_samples_split,\n",
    "#                'min_samples_leaf': min_samples_leaf,\n",
    "#                'bootstrap': bootstrap}\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a57de34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': [20, 22, 24],\n",
      " 'min_samples_split': [2, 4, 6],\n",
      " 'n_estimators': [100, 200, 300, 400]}\n"
     ]
    }
   ],
   "source": [
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab162ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26c4fd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5a4d3d",
   "metadata": {},
   "source": [
    "Finally, fit the RandomizedSearchCV object to the data frames containing features and labels and print the optimal hyperparameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27303281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164910 164910\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/divya/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:285: UserWarning: The total space of parameters 36 is smaller than n_iter=100. Running 36 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 100, 'min_samples_split': 2, 'max_depth': 20}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the random search model\n",
    "print(len(x_train_new), len(y_train_new))\n",
    "rf_random.fit(x_train_new, y_train_new)\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9e4ce7",
   "metadata": {},
   "source": [
    "# Train the Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba2a7e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAndTestRandomForest(_bootstrap, _max_depth,_max_features,\n",
    "                            _min_samples_leaf, _min_samples_split, \n",
    "                            _n_estimators):\n",
    "    clf = RandomForestClassifier(max_depth=_max_depth, \n",
    "                                 bootstrap = _bootstrap, \n",
    "                                 max_features = _max_features,\n",
    "                                 min_samples_leaf = _min_samples_leaf, \n",
    "                                 min_samples_split = _min_samples_split, \n",
    "                                 n_estimators = _n_estimators)\n",
    "    # Train Random Forest Classifer\n",
    "    clf = clf.fit(x_train_new,y_train_new)\n",
    "    #Predict the response for test dataset\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7409cd",
   "metadata": {},
   "source": [
    "# Test the model and find out its accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440cfd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tellAcurracyOfModel(clf):\n",
    "    y_pred = clf.predict(x_test)\n",
    "    # Model Accuracy, how often is the classifier correct?\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a464ff7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9170fb79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36d026fb",
   "metadata": {},
   "source": [
    "# Classification with RF after MinMax Scaling + Dimension Reduction (using PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc5ed50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: make one function of the entire fucntionality and call it for different datasets and find accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ad2380",
   "metadata": {},
   "source": [
    "# Classification with RF after MinMax Scaling + Correlation analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
