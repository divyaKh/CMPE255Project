{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16a6780b",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "\n",
    "- Random Forest is combination of many decision trees\n",
    "- It is a classification algorithm.\n",
    "\n",
    "Why do we need Random Forest over Decision Trees?\n",
    "- Though Decision Trees are easy to build, use and interpret, but they are inaccurate\n",
    "- DTs are not very good with unseen data so our Model may not work as desired\n",
    "- Random Forest = Simplicity of DT + Very Good Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36157ca5",
   "metadata": {},
   "source": [
    "## Input\n",
    "\n",
    "1. .csv - produced by pre_processing.ipynb\n",
    "2. The pre_processed input data includes following techniques:\n",
    "    #TODO\n",
    "\n",
    "## Output/Analysis\n",
    "\n",
    "1. Visualising the accuracy of RF with k-fold validation.\n",
    "2. Comparing the accurancy of RF model with and without PCA.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a4aed72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "76d0b02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    return pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e77ddf2",
   "metadata": {},
   "source": [
    "# Spilt the input file into test and train dataset\n",
    "\n",
    "I/P: dataframe\n",
    "\n",
    "O/P: x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d8c9e261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_training(network_data):\n",
    "    x = network_data.iloc[:,list(range(1,206))]\n",
    "    y = network_data.iloc[:,206]\n",
    "    print(x)\n",
    "    print(y)\n",
    "    print(\"Shape of x: \", x.shape)\n",
    "    print(\"Shape of y: \", y.shape)\n",
    "    return train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9ffff1",
   "metadata": {},
   "source": [
    "# Split the train dataset into train and Cross validation dataset\n",
    "\n",
    "I/P: x_train, y_train\n",
    "\n",
    "O/P: x_train_new, x_cv, y_train_new, y_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "56fd1384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitIntoTrainAndCV(x_train,y_train):\n",
    "    # Splitting train in train and cv data\n",
    "    _x_train_new, _x_cv, _y_train_new, _y_cv = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "    print(_x_train_new.shape, _y_train_new.shape, _x_cv.shape, _y_cv.shape)\n",
    "    return {'x_train_new':_x_train_new, 'x_cv':_x_cv, 'y_train_new': _y_train_new, 'y_cv':_y_cv}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3528006",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning for Random Forest\n",
    "\n",
    "The following hyperparamter tuning has taken reference from:\n",
    "1. https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "2. https://medium.com/@ODSC/optimizing-hyperparameters-for-random-forest-algorithms-in-scikit-learn-d60b7aa07ead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ffeb1df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514106f7",
   "metadata": {},
   "source": [
    "Instead of all the above the parameters, we will just focus on tuning a few as given below:\n",
    "We will try adjusting a few of the following set of hyperparameters:\n",
    "1. n_estimators = number of trees in the foreset\n",
    "2. max_features = max number of features considered for splitting a node\n",
    "3. max_depth = max number of levels in each decision tree\n",
    "4. min_samples_split = min number of data points placed in a node before the node is split\n",
    "5. min_samples_leaf = min number of data points allowed in a leaf node\n",
    "6. bootstrap = method for sampling data points (with or without replacement)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ad6de9",
   "metadata": {},
   "source": [
    "To use RandomizedSearchCV, we first need to create a parameter grid to sample from during fitting:\n",
    "\n",
    "Params From reference github\n",
    "- n_estimators=[100,200,300,400]\n",
    "- max_features = Not included\n",
    "- max_depth = [20,22,24]\n",
    "- min_samples_split = [2,4,6]\n",
    "- min_samples_leaf = not included\n",
    "- bootstrap = not included\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4a379a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f83ae7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creatingRandomGrid():\n",
    "    # Number of trees in random forest\n",
    "    n_estimators = [100,200,300,400]\n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = [20,22,24]\n",
    "    # Minimum number of samples required to split a node\n",
    "    min_samples_split = [2,4,6]\n",
    "    # Create the random grid\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split}\n",
    "    return random_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f55de400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepToFindOptimalHyperParams(random_grid):\n",
    "    # Use the random grid to search for best hyperparameters\n",
    "    # First create the base model to tune\n",
    "    rf = RandomForestRegressor()\n",
    "    \n",
    "    # Random search of parameters, using 3 fold cross validation, \n",
    "    # search across 100 different combinations, and use all available cores\n",
    "    rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, \n",
    "                                   n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "    return rf_random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5a4d3d",
   "metadata": {},
   "source": [
    "Finally, fit the RandomizedSearchCV object to the data frames containing features and labels and print the optimal hyperparameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "27303281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findBestHyperParameters(rf_random, x_train_new, y_train_new):\n",
    "    # Fit the random search model\n",
    "    print(len(x_train_new), len(y_train_new))\n",
    "    rf_random.fit(x_train_new, y_train_new)\n",
    "    bestParamsDict = rf_random.best_params_\n",
    "    return bestParamsDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9e4ce7",
   "metadata": {},
   "source": [
    "# Train the Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ba2a7e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAndTestRandomForest(_max_depth,\n",
    "                            _min_samples_leaf,\n",
    "                            _n_estimators,x_train_new,y_train_new):\n",
    "    clf = RandomForestClassifier(max_depth=_max_depth, \n",
    "                                 min_samples_split = _min_samples_split, \n",
    "                                 n_estimators = _n_estimators)\n",
    "    # Train Random Forest Classifer\n",
    "    clf = clf.fit(x_train_new,y_train_new)\n",
    "    #Predict the response for test dataset\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7409cd",
   "metadata": {},
   "source": [
    "# Test the model and find out its accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "440cfd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tellAcurracyOfModel(clf):\n",
    "    y_pred = clf.predict(x_test)\n",
    "    # Model Accuracy, how often is the classifier correct?\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c609a94a",
   "metadata": {},
   "source": [
    "# Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "feb78669",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(network_data):\n",
    "        \n",
    "    x_train,x_test,y_train,y_test = prep_training(network_data)\n",
    "    \n",
    "    newDict = splitIntoTrainAndCV(x_train,y_train)\n",
    "    x_train_new = newDict['x_train_new']\n",
    "    x_cv = newDict['x_cv']\n",
    "    y_train_new = newDict['y_train_new']\n",
    "    y_cv = newDict['y_cv']\n",
    "                    \n",
    "    random_grid = creatingRandomGrid()\n",
    "    pprint(random_grid)\n",
    "    rf_random = prepToFindOptimalHyperParams(random_grid)\n",
    "    bestParamsDict = findBestHyperParameters(rf_random, x_train_new, y_train_new)\n",
    "    \n",
    "    #TODO : Grab this dict values in paramters\n",
    "    #and pass those params to below function\n",
    "    _n_estimators = bestParamsDict['n_estimators']\n",
    "    _min_samples_split = bestParamsDict['min_samples_split']\n",
    "    _max_depth = bestParamsDict['max_depth']\n",
    "    \n",
    "    clf = trainAndTestRandomForest(_max_depth,_min_samples_leaf,_n_estimators,x_train_new,y_train_new)\n",
    "    tellAcurracyOfModel(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73d1131",
   "metadata": {},
   "source": [
    "# Classification with RF after MinMax Scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c477d47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         spkts     dpkts    sbytes    dbytes      rate      sttl      dttl  \\\n",
      "0     0.000094  0.000000  0.000033  0.000000  0.090909  0.996078  0.000000   \n",
      "1     0.000094  0.000000  0.000121  0.000000  0.125000  0.996078  0.000000   \n",
      "2     0.000094  0.000000  0.000073  0.000000  0.200000  0.996078  0.000000   \n",
      "3     0.000094  0.000000  0.000061  0.000000  0.166667  0.996078  0.000000   \n",
      "4     0.000094  0.000000  0.000146  0.000000  0.100000  0.996078  0.000000   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "7367  0.000845  0.000726  0.000065  0.000024  0.000011  0.996078  0.992126   \n",
      "7368  0.001221  0.000545  0.000448  0.000018  0.000031  0.996078  0.992126   \n",
      "7369  0.000094  0.000000  0.000012  0.000000  0.200000  0.996078  0.000000   \n",
      "7370  0.000094  0.000000  0.000012  0.000000  0.166667  0.996078  0.000000   \n",
      "7371  0.000094  0.000000  0.000012  0.000000  0.125000  0.996078  0.000000   \n",
      "\n",
      "             sload     dload     sloss  ...  attack_cat_Analysis  \\\n",
      "0     3.012085e-02  0.000000  0.000000  ...                  0.0   \n",
      "1     1.471276e-01  0.000000  0.000000  ...                  0.0   \n",
      "2     1.426854e-01  0.000000  0.000000  ...                  0.0   \n",
      "3     1.002004e-01  0.000000  0.000000  ...                  0.0   \n",
      "4     1.420174e-01  0.000000  0.000000  ...                  0.0   \n",
      "...            ...       ...       ...  ...                  ...   \n",
      "7367  7.091126e-07  0.000068  0.000376  ...                  0.0   \n",
      "7368  1.287892e-05  0.000129  0.000752  ...                  0.0   \n",
      "7369  2.672011e-02  0.000000  0.000000  ...                  0.0   \n",
      "7370  2.226675e-02  0.000000  0.000000  ...                  0.0   \n",
      "7371  1.670007e-02  0.000000  0.000000  ...                  NaN   \n",
      "\n",
      "      attack_cat_Backdoor  attack_cat_DoS  attack_cat_Exploits  \\\n",
      "0                     0.0             0.0                  0.0   \n",
      "1                     0.0             0.0                  0.0   \n",
      "2                     0.0             0.0                  0.0   \n",
      "3                     0.0             0.0                  0.0   \n",
      "4                     0.0             0.0                  0.0   \n",
      "...                   ...             ...                  ...   \n",
      "7367                  0.0             0.0                  1.0   \n",
      "7368                  0.0             0.0                  1.0   \n",
      "7369                  0.0             1.0                  0.0   \n",
      "7370                  0.0             0.0                  1.0   \n",
      "7371                  NaN             NaN                  NaN   \n",
      "\n",
      "      attack_cat_Fuzzers  attack_cat_Generic  attack_cat_Normal  \\\n",
      "0                    0.0                 0.0                1.0   \n",
      "1                    0.0                 0.0                1.0   \n",
      "2                    0.0                 0.0                1.0   \n",
      "3                    0.0                 0.0                1.0   \n",
      "4                    0.0                 0.0                1.0   \n",
      "...                  ...                 ...                ...   \n",
      "7367                 0.0                 0.0                0.0   \n",
      "7368                 0.0                 0.0                0.0   \n",
      "7369                 0.0                 0.0                0.0   \n",
      "7370                 0.0                 0.0                0.0   \n",
      "7371                 NaN                 NaN                NaN   \n",
      "\n",
      "      attack_cat_Reconnaissance  attack_cat_Shellcode  attack_cat_Worms  \n",
      "0                           0.0                   0.0               0.0  \n",
      "1                           0.0                   0.0               0.0  \n",
      "2                           0.0                   0.0               0.0  \n",
      "3                           0.0                   0.0               0.0  \n",
      "4                           0.0                   0.0               0.0  \n",
      "...                         ...                   ...               ...  \n",
      "7367                        0.0                   0.0               0.0  \n",
      "7368                        0.0                   0.0               0.0  \n",
      "7369                        0.0                   0.0               0.0  \n",
      "7370                        0.0                   0.0               0.0  \n",
      "7371                        NaN                   NaN               NaN  \n",
      "\n",
      "[7372 rows x 205 columns]\n",
      "0       0.0\n",
      "1       0.0\n",
      "2       0.0\n",
      "3       0.0\n",
      "4       0.0\n",
      "       ... \n",
      "7367    1.0\n",
      "7368    1.0\n",
      "7369    1.0\n",
      "7370    1.0\n",
      "7371    NaN\n",
      "Name: label, Length: 7372, dtype: float64\n",
      "Shape of x:  (7372, 205)\n",
      "Shape of y:  (7372,)\n",
      "(4717, 205) (4717,) (1180, 205) (1180,)\n",
      "{'max_depth': [20, 22, 24],\n",
      " 'min_samples_split': [2, 4, 6],\n",
      " 'n_estimators': [100, 200, 300, 400]}\n",
      "4717 4717\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/divya/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:285: UserWarning: The total space of parameters 36 is smaller than n_iter=100. Running 36 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/Users/divya/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-81b88a2999c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnetwork_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data_minmax.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-52-7248520aa618>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(network_data)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mrf_random\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepToFindOptimalHyperParams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mbestParamsDict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfindBestHyperParameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf_random\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#TODO : Grab this dict values in paramters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-44b06410ceb8>\u001b[0m in \u001b[0;36mfindBestHyperParameters\u001b[0;34m(rf_random, x_train_new, y_train_new)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Fit the random search model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mrf_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mbestParamsDict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbestParamsDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    302\u001b[0m                 \u001b[0;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m             )\n\u001b[0;32m--> 304\u001b[0;31m         X, y = self._validate_data(X, y, multi_output=True,\n\u001b[0m\u001b[1;32m    305\u001b[0m                                    accept_sparse=\"csc\", dtype=DTYPE)\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[1;32m    815\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m             _assert_all_finite(array,\n\u001b[0m\u001b[1;32m    664\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m    102\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                     (type_err,\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "network_data = load_data('data_minmax.csv')\n",
    "main(network_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d026fb",
   "metadata": {},
   "source": [
    "# Classification with RF after MinMax Scaling + Dimension Reduction (using PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cca6bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_data = load_data('dataset_minmax_pca.csv')\n",
    "main(network_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ad2380",
   "metadata": {},
   "source": [
    "# Classification with RF after MinMax Scaling + Correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825a9a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_data = load_data('dataset_minmax_corr.csv')\n",
    "main(network_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
