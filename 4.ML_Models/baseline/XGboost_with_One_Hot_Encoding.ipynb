{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f334b6d3",
   "metadata": {},
   "source": [
    "# This is a baseline notebook and it uploads the dataset with one hot encoding and shows overfitting of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c9ad3d",
   "metadata": {},
   "source": [
    "#**Load the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7166f12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_regression\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.datasets import load_iris\n",
    "from numpy import array \n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.datasets import make_friedman1\n",
    "from sklearn.feature_selection import RFE\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import metrics\n",
    "# check accuracy score\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64a0d75b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(219738, 207)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"dataset.csv\")\n",
    "\n",
    "dataset =dataset.fillna(0)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f435875f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(219738, 207)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_minmax = pd.read_csv(\"dataset_minmax.csv\")\n",
    "dataset_minmax.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "276a7628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(219738, 177)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_pca = pd.read_csv(\"dataset_pca.csv\")\n",
    "dataset_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e628ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(219738, 207)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_minmax_corr =pd.read_csv(\"dataset_minmax_corr.csv\")\n",
    "dataset_minmax_corr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207aa5d9",
   "metadata": {},
   "source": [
    "#Xgboost without any preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68f8f1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dataset.drop(columns=['label'])\n",
    "y=dataset['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7bc3356",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51a07cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nancy Saxena\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15353     0]\n",
      " [    0 28595]]\n",
      "1.0\n",
      "XGBoost model accuracy score: 1.0000\n",
      "[2.7028822e-05 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.6852766e-05\n",
      " 2.0135463e-05 1.1415764e-05 3.4153221e-05 4.6948244e-05 2.4129917e-05\n",
      " 1.7399763e-05 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 1.9029127e-05 4.7992631e-05 1.4576650e-05\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.7006093e-04 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 1.5950889e-05 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 2.4230323e-05 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 9.9950010e-01 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "model1 = xgb.XGBClassifier(max_depth=5,verbosity=0,early_stopping_rounds=1,gamma=0.1,n_trees=2)\n",
    "model1.fit(X_train, y_train)\n",
    "predicted_y = model1.predict(X_test)\n",
    "print(metrics.confusion_matrix(y_test, predicted_y))\n",
    "print((accuracy_score(y_test, predicted_y)))\n",
    "print('XGBoost model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, predicted_y)))\n",
    "model1.feature_importances_\n",
    "\n",
    "pyplot.bar(range(len(model1.feature_importances_)), model1.feature_importances_)\n",
    "print(model1.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f548e1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tried with differnt parameters the model was still over fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb7c0e0",
   "metadata": {},
   "source": [
    "#XGBoost with pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dff68712",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nancy Saxena\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     22973\n",
      "         1.0       1.00      1.00      1.00     42949\n",
      "\n",
      "    accuracy                           1.00     65922\n",
      "   macro avg       1.00      1.00      1.00     65922\n",
      "weighted avg       1.00      1.00      1.00     65922\n",
      "\n",
      "[[22968     5]\n",
      " [    3 42946]]\n",
      "XGBoost model accuracy score: 0.9999\n"
     ]
    }
   ],
   "source": [
    "X=dataset_pca.drop(columns=['label'])\n",
    "y=dataset_pca['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=100)\n",
    "model = xgb.XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "predicted_y = model.predict(X_test)\n",
    "print(metrics.classification_report(y_test, predicted_y))\n",
    "print(metrics.confusion_matrix(y_test, predicted_y))\n",
    "\n",
    "print('XGBoost model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, predicted_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a79b305",
   "metadata": {},
   "source": [
    "#XGBoost with Minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa83769e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nancy Saxena\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     15347\n",
      "         1.0       1.00      1.00      1.00     28601\n",
      "\n",
      "    accuracy                           1.00     43948\n",
      "   macro avg       1.00      1.00      1.00     43948\n",
      "weighted avg       1.00      1.00      1.00     43948\n",
      "\n",
      "[[15347     0]\n",
      " [    0 28601]]\n",
      "XGBoost model accuracy score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "X=dataset_minmax.drop(columns=['label'])\n",
    "y=dataset_minmax['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "model = xgb.XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "predicted_y = model.predict(X_test)\n",
    "print(metrics.classification_report(y_test, predicted_y))\n",
    "print(metrics.confusion_matrix(y_test, predicted_y))\n",
    "\n",
    "print('XGBoost model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, predicted_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2585dad7",
   "metadata": {},
   "source": [
    "#XGBoost with minmax and corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0776caf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nancy Saxena\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     15278\n",
      "         1.0       1.00      1.00      1.00     28670\n",
      "\n",
      "    accuracy                           1.00     43948\n",
      "   macro avg       1.00      1.00      1.00     43948\n",
      "weighted avg       1.00      1.00      1.00     43948\n",
      "\n",
      "[[15278     0]\n",
      " [    0 28670]]\n",
      "XGBoost model accuracy score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "X=dataset_minmax_corr.drop(columns=['label'])\n",
    "y=dataset_minmax_corr['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "model = xgb.XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "predicted_y = model.predict(X_test)\n",
    "print(metrics.classification_report(y_test, predicted_y))\n",
    "print(metrics.confusion_matrix(y_test, predicted_y))\n",
    "\n",
    "print('XGBoost model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, predicted_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae120ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
